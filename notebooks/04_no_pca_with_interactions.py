# -*- coding: utf-8 -*-
"""MachineLearningIncrementalCapstoneNotPCA.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1MKl6useL8zV1k_kWtxkoxEsmUuAicEbL

# Machine Learning: Incremental Capstone

https://drive.google.com/drive/folders/1RFvzO7Eyidp4M9GCSO93izHXnaBFfQbF

('FloridaBikeRentals.csv')

Carllos Watts-Nogueira

Due: Jul 12 by 12:59am

# Task 1: Feature engineering
"""

#  Import Libraries - Packages
import pandas as pd
from sklearn.preprocessing import StandardScaler #, OneHotEncoder
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline

from sklearn.decomposition import PCA

# Load the data - Inspect Data

# import chardet
# with open('FloridaBikeRentals.csv', 'rb') as f:
#     result = chardet.detect(f.read())
# print(result['encoding'])

# Load the data
df_main = pd.read_csv('FloridaBikeRentals.csv') # after clean Temperature(°C) and Dew point temperature(°C) to Temperature(C) and Dew point temperature(C)

# 1) Analyze the provided dataset and select relevant features
df_main.head()

df_main.info()

# copy
df = df_main.copy(deep=True)

# Change Date from object type to --> datetime
df['Date'] = pd.to_datetime(df['Date'], format='%d-%m-%Y')

# Change Hour from int64 to --> int8
df['Hour'] = df['Hour'].astype('int8')

# date + hour df.[DateTime]
df['DateTime'] = df['Date'] + pd.to_timedelta(df['Hour'], unit='h')

# drop date, drop hour
df.drop(['Date', 'Hour'], axis=1, inplace=True)

# Recommended to improve performance/memory usage and efficiency?

# int64 to int32
df['Rented Bike Count'] = df['Rented Bike Count'].astype('int32')
df['Visibility (10m)'] = df['Visibility (10m)'].astype('int32')
df['Humidity(%)'] = df['Humidity(%)'].astype('int32')

# float64 to float32
df['Temperature(C)'] = df['Temperature(C)'].astype('float32')
df['Wind speed (m/s)'] = df['Wind speed (m/s)'].astype('float32')
df['Dew point temperature(C)'] = df['Dew point temperature(C)'].astype('float32')
df['Solar Radiation (MJ/m2)'] = df['Solar Radiation (MJ/m2)'].astype('float32')
df['Rainfall(mm)'] = df['Rainfall(mm)'].astype('float32')
df['Snowfall (cm)'] = df['Snowfall (cm)'].astype('float32')

# memory
before = df_main.memory_usage(deep=True).sum()
after = df.memory_usage(deep=True).sum()
print(f"Memory reduced from {before / 1024:.2f} KB to {after / 1024:.2f} KB")

df.describe()

df.duplicated().sum() #= 0

# handle missing values
df.isnull().sum()   #= 0

df['Seasons'].unique()

df['Holiday'].unique()

df['Functioning Day'].unique()

df.shape

df.corr(numeric_only=True)

"""Target = Rented Bike Count

Feacture Correlation analysis

Feature Correlation Analysis
Summary of how each feature correlates with the target (Rented Bike Count):

| Temperature(C) | +0.54 | Strong positive correlation—warmer weather boosts rentals |

| Dew point temperature(C) | +0.38 | Closely tied to temperature, also positively correlated |

| Solar Radiation (MJ/m2) | +0.26 | Sunny conditions encourage biking |

| Visibility (10m) | +0.20 | Clear visibility slightly improves rentals |

| Wind speed (m/s) | +0.12 | Mild wind may be tolerable; extreme wind likely reduces rentals |

| Humidity(%) | –0.20 | High humidity discourages biking |

| Rainfall(mm) | –0.12 | Rain reduces rentals |

| Snowfall (cm) | –0.14 | Snow has a negative impact, though rare in Florida |

"""

# numeric columns
col_numerics = df.select_dtypes(include='number').columns.tolist()
col_numerics

# not numeric columns
col_not_numerics = df.select_dtypes(exclude='number').columns.tolist()
col_not_numerics

# Extract week day (0 = M, 6 = S)
df['Weekday'] = df['DateTime'].dt.weekday

# Flag weekend
df['IsWeekend'] = df['Weekday'].isin([5, 6]).astype(int)

# Extract month
df['Month'] = df['DateTime'].dt.month

# Extract hour
df['Hour'] = df['DateTime'].dt.hour

# Encode categorical variable
categorical_features = ['Seasons', 'Holiday', 'Functioning Day']
df_encoded = pd.get_dummies(df, columns=categorical_features, drop_first=True)

# Col numeric
numerical_features = ['Temperature(C)', 'Humidity(%)', 'Wind speed (m/s)',
                      'Visibility (10m)', 'Dew point temperature(C)',
                      'Solar Radiation (MJ/m2)', 'Rainfall(mm)',
                      'Snowfall (cm)']

#  Scale the numerical features using StandardScaler
scaler = StandardScaler()
df_encoded[numerical_features] = scaler.fit_transform(df_encoded[numerical_features])

# 2) Create new features such as:
# Interaction features

# Combine temperature and humidity to capture their joint influence on bike rentals.
# For example, hot and humid days may reduce bike usage due to discomfort.
df_encoded['Temp_Humidity'] = df_encoded['Temperature(C)'] * df_encoded['Humidity(%)']

# Multiply hour of day by weekday to model time-of-week patterns.
# This can help the model recognize that, say, 8 AM on Monday behaves differently than 8 AM on Saturday.
df_encoded['Hour_Weekday'] = df_encoded['Hour'] * df_encoded['Weekday']

# Interaction between wind speed and visibility — useful for modeling harsh weather conditions.
# Poor visibility with strong winds may discourage rentals more than either variable alone.
df_encoded['Wind_Visibility'] = df_encoded['Wind speed (m/s)'] * df_encoded['Visibility (10m)']

# Combine temperature with month to model seasonal temperature trends.
# For instance, 25°C in March might mean something different than 25°C in August.
df_encoded['Temp_Month'] = df_encoded['Temperature(C)'] * df_encoded['Month']

# Multiply Temperature by 10 for standardization
# df['Temperature(C)'] = df['Temperature(C)'] * 10
# df

# not need to manually multiply it by 10, applying StandardScaler

# Save the processed dataset as "bike_rental_features.csv"
df_encoded.to_csv('bike_rental_features.csv', index=False)

df_encoded.head()

df_encoded.info()

df_encoded.describe()

df_encoded.corr(numeric_only=True)

"""#  Task 2: Model building"""

# Import libraries
from sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet, RidgeCV
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score
from sklearn.model_selection import train_test_split, GridSearchCV
import matplotlib.pyplot as plt

# Define X and y — apenas com PCA
X = df_encoded.drop(columns=['Rented Bike Count', 'DateTime'])
y = df_encoded['Rented Bike Count']

# Split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

#  2.1) Linear Regression

# Model LinearRegression
model_lr = LinearRegression()
model_lr.fit(X_train, y_train)

# Predictions
y_pred = model_lr.predict(X_test)

print("Linear Regression:")
print("MSE:", mean_squared_error(y_test, y_pred))
print("MAE:", mean_absolute_error(y_test, y_pred))
print("R²:", r2_score(y_test, y_pred))

#  2.2) Ridge Regression (L2 Regularization)

# Instantiate Ridge model with default alpha
ridge_model = Ridge(alpha=1.0)
ridge_model.fit(X_train, y_train)

# Predictions
y_pred_ridge = ridge_model.predict(X_test)

# Evaluation
print("Ridge Regression:")
print("MAE:", round(mean_absolute_error(y_test, y_pred_ridge), 2))
print("MSE:", round(mean_squared_error(y_test, y_pred_ridge), 2))
print("R²:", round(r2_score(y_test, y_pred_ridge), 4))

#  2.3) Lasso Regression (L1 Regularization)

# Train Lasso with default alpha
lasso_model = Lasso(alpha=1.0, max_iter=10000)
lasso_model.fit(X_train, y_train)

# Predict
y_pred_lasso = lasso_model.predict(X_test)

# Evaluate
print("Lasso Regression:")
print("MAE:", round(mean_absolute_error(y_test, y_pred_lasso), 2))
print("MSE:", round(mean_squared_error(y_test, y_pred_lasso), 2))
print("R²:", round(r2_score(y_test, y_pred_lasso), 4))

#  2.4) Elastic Net Regression

# Instantiate ElasticNet with default alpha and l1_ratio
elastic_model = ElasticNet(alpha=1.0, l1_ratio=0.5, max_iter=10000)
elastic_model.fit(X_train, y_train)

# Predictions
y_pred_enet = elastic_model.predict(X_test)

# Evaluation
print("Elastic Net Regression:")
print("MAE:", round(mean_absolute_error(y_test, y_pred_enet), 2))
print("MSE:", round(mean_squared_error(y_test, y_pred_enet), 2))
print("R²:", round(r2_score(y_test, y_pred_enet), 4))

#  2.5) Perform hyperparameter tuning using GridSearchCV

# Define Ridge and the hyperparameter grid
ridge = Ridge()
param_grid = {
    'alpha': [0.01, 0.1, 1.0, 10.0, 100.0],
    'fit_intercept': [True, False],
    'solver': ['auto', 'lsqr'],
    'max_iter': [10000, 20000, 50000]
}

# GridSearchCV
grid = GridSearchCV(estimator=ridge, param_grid=param_grid, cv=5, scoring='neg_mean_squared_error')
grid.fit(X_train, y_train)

# Best model and evaluate
best_ridge = grid.best_estimator_
print("Best Parameters:", grid.best_params_)

# Evaluate
y_pred = best_ridge.predict(X_test)
print("Tuned Ridge Regression:")
print("MAE:", round(mean_absolute_error(y_test, y_pred), 2))
print("MSE:", round(mean_squared_error(y_test, y_pred), 2))
print("R²:", round(r2_score(y_test, y_pred), 4))

#  2.6) Evaluate model performance using:
# Mean Absolute Error (MAE)
# Mean Squared Error (MSE)
# R-squared (R²)

#  Consolidate Models

models = {
    'Linear': LinearRegression(),
    'Ridge': Ridge(),
    'Lasso': Lasso(),
    'ElasticNet': ElasticNet()
}

# param
param_grid = {
    'Ridge': {
        'alpha': [0.1, 1, 10],
        'max_iter': [50000]
    },
    'Lasso': {
        'alpha': [0.001, 0.01, 0.1],
        'max_iter': [50000]
    },
    'ElasticNet': {
        'alpha': [0.1, 1],
        'l1_ratio': [0.2, 0.5, 0.8],
        'max_iter': [50000]
    }
}

results = {}

for name, model in models.items():
    if name in param_grid:
        grid = GridSearchCV(model, param_grid[name], cv=5, scoring='neg_mean_squared_error', n_jobs=-1)
        grid.fit(X_train, y_train)
        best_model = grid.best_estimator_
    else:
        best_model = model.fit(X_train, y_train)

    y_pred = best_model.predict(X_test)

    results[name] = {
        'MAE': mean_absolute_error(y_test, y_pred),
        'MSE': mean_squared_error(y_test, y_pred),
        'R2': r2_score(y_test, y_pred)
    }

# print
print(pd.DataFrame(results).T.round(3))

"""# Task 3: Model building with polynomial features (45 mins)"""

# import libraries
from sklearn.preprocessing import PolynomialFeatures
from sklearn.pipeline import make_pipeline
import joblib

# Create polynomial features for selected numerical columns
# Train models with polynomial features to capture non-linear relationships
# Compare results with linear models to assess improvements
# Save the best-performing model

poly = PolynomialFeatures(degree=2, include_bias=False)
model = make_pipeline(poly, LinearRegression())

model.fit(X_train, y_train)
y_poly_pred = model.predict(X_test)

# evaluate
print('MAE:', mean_absolute_error(y_test, y_poly_pred))
print('MSE:', mean_squared_error(y_test, y_poly_pred))
print('R²:', r2_score(y_test, y_poly_pred))

# Save
joblib.dump(model, 'best_poly_model.pkl')

# print best_poly_model.pkl, joblib.dump model
print(model)

"""# Task 4: Model evaluation and validation (45 mins)"""

# import libraries
from sklearn.model_selection import cross_val_score
import numpy as np

# Perform cross-validation techniques to validate model performance (on both models- With Polynomial Features and without Polynomial Features)
# Assess models using test data
# Compare results across different regression models

poly_models = {
    'Poly_Linear': make_pipeline(
        StandardScaler(),
        PolynomialFeatures(degree=2, include_bias=False),
        LinearRegression()
    ),
    'Poly_Ridge': make_pipeline(
        StandardScaler(),
        PolynomialFeatures(degree=2, include_bias=False),
        Ridge(alpha=1.0)
    ),
    'Poly_Lasso': make_pipeline(
        StandardScaler(),
        PolynomialFeatures(degree=2, include_bias=False),
        Lasso(alpha=0.1, max_iter=100_000)
    )
}

# Validation
for name, model in poly_models.items():
    scores = cross_val_score(model, X_train, y_train, cv=5, scoring='r2')
    print(f"{name} R² CV Mean: {scores.mean():.4f} | Std: {scores.std():.4f}")

# Ridge
ridge = Ridge(alpha=1)
scores = cross_val_score(ridge, X, y, scoring='r2', cv=5)
print('R² mean (cross-val):', np.mean(scores))

# Base models with adjusted max_iter where needed
models = {
    'Linear': LinearRegression(),
    'Ridge': Ridge(alpha=1.0),
    'Lasso': Lasso(alpha=0.1, max_iter=100000),
    'ElasticNet': ElasticNet(alpha=0.1, l1_ratio=0.5, max_iter=100000)
}

# Polynomial models with scaling
poly_models = {
    'Poly_Linear': make_pipeline(StandardScaler(), PolynomialFeatures(degree=2, include_bias=False), LinearRegression()),
    'Poly_Ridge': make_pipeline(StandardScaler(), PolynomialFeatures(degree=2, include_bias=False), Ridge(alpha=1.0)),
    'Poly_Lasso': make_pipeline(StandardScaler(), PolynomialFeatures(degree=2, include_bias=False), Lasso(alpha=0.1, max_iter=100000))
}

# Evaluation function
def evaluate_model(name, model, X_train, X_test):
    model.fit(X_train, y_train)
    y_pred = model.predict(X_test)
    return {
        'MAE': mean_absolute_error(y_test, y_pred),
        'MSE': mean_squared_error(y_test, y_pred),
        'R2': r2_score(y_test, y_pred)
    }

# Run evaluations
results = {}

for name, model in models.items():
    results[name] = evaluate_model(name, model, X_train, X_test)

for name, model in poly_models.items():
    results[name] = evaluate_model(name, model, X_train, X_test)

# Display results
print(pd.DataFrame(results).T.round(3))

"""# Task 5: Reporting and insights (30 mins)"""

# 1.    Summarize findings and key takeaways from the analysis
# 2.    Discuss feature importance and business implications
# 3.    Provide recommendations for further improvements

"""Summary of What I Learned from Modeling Bike Rentals

Performance of the Models

- At first, I tested some linear models like Linear Regression, Ridge, and Lasso. They did okay — they explained around 55% of the variation in bike rentals, which helped me understand basic relationships in the data. Later, when I added polynomial features and created interaction terms, things improved a lot. My best models reached an R² of almost 0.74 and had much lower prediction errors. It showed me that non-linear models can capture more realistic patterns in user behavior.

Making the Models More Stable

- When I introduced polynomial features, I noticed the models became unstable or didn’t converge well. After researching, I learned that higher dimensionality can make models harder to train. So I adjusted the max_iter parameter to let them run longer, and added regularization like Ridge and Lasso to control the complexity. This made the models much more consistent, especially during cross-validation.

Business Implications:

- These models could really help bike rental companies. For example, if they know which hours or weather conditions lead to more rentals, they can plan staff better or prepare more bikes in advance. Also, dynamic pricing could be introduced during peak demand. Even weather alerts could be sent to users if poor conditions are predicted — or used to rebalance bike locations across the city.

Recommendations for Further Improvements

- I’d like to try some tree-based models next, like RandomForestRegressor or XGBoost, since they might capture more complex decision boundaries. Also, I think expanding feature engineering could help — like binning hours into time-of-day categories (Morning, Afternoon…), or adding more interaction terms between weather features. Finally, I want to plot residuals and maybe build a dashboard to visualize predictions and help make business decisions.

"""

# plot L Regression modal
plt.figure(figsize=(8, 5))
plt.scatter(y_test, y_pred, alpha=0.6, color='blue')
plt.xlabel("Actual Values")
plt.ylabel("Predicted Values")
plt.title("Linear Regression: Actual vs Predicted")
plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], color='red', linewidth=2)  # Reference line
plt.grid(True)
plt.show()

# Plot Ridge Regression
plt.figure(figsize=(8, 5))
plt.scatter(y_test, y_pred_ridge, alpha=0.6, color='green')
plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], color='red', linewidth=2)
plt.xlabel("Actual Values")
plt.ylabel("Predicted Values")
plt.title("Ridge Regression: Actual vs Predicted")
plt.grid(True)
plt.show()

# Plot Lasso Regression
plt.figure(figsize=(8, 5))
plt.scatter(y_test, y_pred_lasso, alpha=0.6, color='teal')
plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], color='red', linewidth=2)
plt.xlabel("Actual Values")
plt.ylabel("Predicted Values")
plt.title("Lasso Regression: Actual vs Predicted")
plt.grid(True)
plt.show()

# Plot Elastic Net Regrression
plt.figure(figsize=(8, 5))
plt.scatter(y_test, y_pred_enet, alpha=0.6, color='darkcyan')
plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], color='red', linewidth=2)
plt.xlabel("Actual Values")
plt.ylabel("Predicted Values")
plt.title("Elastic Net: Actual vs Predicted")
plt.grid(True)
plt.show()

# Plot Perfom hyperparameter tuning using GridSearchCV
plt.figure(figsize=(8, 5))
plt.scatter(y_test, y_pred, alpha=0.6, color='navy')
plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], color='red', linewidth=2)
plt.xlabel("Actual Values")
plt.ylabel("Predicted Values")
plt.title("Tuned Ridge: Actual vs Predicted")
plt.grid(True)
plt.show()

# Plot Poly_Linear
model = poly_models['Poly_Linear']
model.fit(X_train, y_train)
y_pred = model.predict(X_test)

plt.figure(figsize=(8, 5))
plt.scatter(y_test, y_pred, alpha=0.6, color='blue')
plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], color='red', linewidth=2)
plt.xlabel("Actual Values")
plt.ylabel("Predicted Values")
plt.title("Poly_Linear: Actual vs Predicted")
plt.grid(True)
plt.tight_layout()
plt.show()

# Plot Poly Ridge
model = poly_models['Poly_Ridge']
model.fit(X_train, y_train)
y_pred = model.predict(X_test)

plt.figure(figsize=(8, 5))
plt.scatter(y_test, y_pred, alpha=0.6, color='green')
plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], color='red', linewidth=2)
plt.xlabel("Actual Values")
plt.ylabel("Predicted Values")
plt.title("Poly_Ridge: Actual vs Predicted")
plt.grid(True)
plt.tight_layout()
plt.show()

# Plot Poly Lasso
model = poly_models['Poly_Lasso']
model.fit(X_train, y_train)
y_pred = model.predict(X_test)

plt.figure(figsize=(8, 5))
plt.scatter(y_test, y_pred, alpha=0.6, color='purple')
plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], color='red', linewidth=2)
plt.xlabel("Actual Values")
plt.ylabel("Predicted Values")
plt.title("Poly_Lasso: Actual vs Predicted")
plt.grid(True)
plt.tight_layout()
plt.show()